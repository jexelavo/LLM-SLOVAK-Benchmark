{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f91af6ed",
   "metadata": {},
   "source": [
    "In this analysis, I apply the same evaluation methods as described in **embeddings_effectivity_final.ipynb**, but to a corpus in which all documents were first **machine-translated into English**.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e58ddd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from mistralai import Mistral\n",
    "import voyageai\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import itertools, numpy as np, pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    v_measure_score, normalized_mutual_info_score,\n",
    "    adjusted_rand_score, silhouette_score, accuracy_score,\n",
    "    precision_recall_fscore_support\n",
    ")\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from collections import Counter\n",
    "import umap\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from kneed import KneeLocator\n",
    "import seaborn as sns\n",
    "from google.cloud import translate_v3 as translate\n",
    "from google.api_core.exceptions import GoogleAPICallError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "808830d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(r\"..\\data\\df_to_app_with_openAI_S_L_voyage_gdoogle_mistral_embeddings_navrh_zakona_obdobie_8_core_clear.parquet\", engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b9eda8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(r\"..\\keys.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf5e0801",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_slovak_embedding_metrics_table(metrics_df, save_path=r\"..\\graphs\\slovak_translate_embedding_effectiveness_metrics.png\"):\n",
    "    \"\"\"\n",
    "    Save Slovak parliamentary embedding clustering metrics as publication-ready PNG\n",
    "    Specialized for 2010-2023 parliamentary transcription corpus analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    # Method 1: Professional academic table with matplotlib\n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Create styled table for Slovak NLP research\n",
    "    table = ax.table(cellText=metrics_df.round(3).values,\n",
    "                    colLabels=['Embedding Model', 'Clustering Method', 'K-Clusters', \n",
    "                              'Precision', 'Recall', 'F1-Score', 'V-Measure', 'ARI'],\n",
    "                    cellLoc='center',\n",
    "                    loc='center',\n",
    "                    bbox=[0, 0, 1, 1])\n",
    "    \n",
    "    # Slovak parliamentary research styling\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1.2, 2.0)\n",
    "    \n",
    "    # Header styling for academic publication\n",
    "    for i in range(len(metrics_df.columns)):\n",
    "        table[(0, i)].set_facecolor('#2E4057')  # Slovak blue theme\n",
    "        table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "        table[(0, i)].set_height(0.1)\n",
    "    \n",
    "    # Color-code by embedding performance for Slovak language\n",
    "    for i in range(1, len(metrics_df) + 1):\n",
    "        # Highlight best performing embeddings for Slovak text\n",
    "        f1_score = float(metrics_df.iloc[i-1]['f1'])\n",
    "        if f1_score > 0.7:  # High performance for Slovak parliamentary text\n",
    "            for j in range(len(metrics_df.columns)):\n",
    "                table[(i, j)].set_facecolor('#E8F5E8')  # Light green\n",
    "        elif f1_score > 0.5:  # Medium performance\n",
    "            for j in range(len(metrics_df.columns)):\n",
    "                table[(i, j)].set_facecolor('#FFF8DC')  # Light yellow\n",
    "        else:  # Low performance for Slovak language\n",
    "            for j in range(len(metrics_df.columns)):\n",
    "                table[(i, j)].set_facecolor('#FFE4E1')  # Light red\n",
    "    \n",
    "    # Title for Slovak parliamentary research\n",
    "    plt.title('Embedding Model Effectiveness on Slovak Parliamentary Transcriptions\\n'\n",
    "              'Clustering Performance Analysis (2010-2023 Corpus)', \n",
    "              fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Add research context subtitle\n",
    "    plt.figtext(0.5, 0.02, 'Novel NLP Procedures for Slovak Language Analysis | Ministry-based Semantic Clustering',\n",
    "                ha='center', fontsize=10, style='italic')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    print(f\"✅ Slovak embedding metrics table saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c17ace40",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "Mistral_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "VOYAGE_API_KEY = os.getenv(\"VOYAGE_API_KEY\")\n",
    "PROJECT_ID = os.getenv(\"GOOGLE_CLOUD_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6feaac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vo = voyageai.Client(api_key=VOYAGE_API_KEY)\n",
    "client_mistral = Mistral(api_key=Mistral_API_KEY)\n",
    "client_google = genai.Client(api_key=google_api_key)\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3857489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_dataframe_column(df, column_to_translate, target_language, project_id):\n",
    "    \"\"\"\n",
    "    Translates a column in a pandas DataFrame using the Google Cloud Translation API.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        column_to_translate (str): The name of the column containing the text to translate.\n",
    "        target_language (str): The language code to translate the text to (e.g., 'en' for English).\n",
    "        project_id (str): Your Google Cloud Project ID.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with a new column containing the translated text.\n",
    "    \"\"\"\n",
    "    # Create a Translation client.\n",
    "    client = translate.TranslationServiceClient()\n",
    "\n",
    "    # Get the location name for the project.\n",
    "    location = \"global\" \n",
    "    parent = f\"projects/{project_id}/locations/{location}\"\n",
    "\n",
    "    # Initialize a list to hold the translated sentences.\n",
    "    translated_texts = []\n",
    "\n",
    "    # Iterate through each row's text and perform the translation.\n",
    "    # Note: For very large datasets, consider batching requests to optimize API usage.\n",
    "    print(f\"Translating column '{column_to_translate}'...\")\n",
    "    for text in df[column_to_translate]:\n",
    "        # Handle cases where the text might be empty or not a string.\n",
    "        if not text or not isinstance(text, str):\n",
    "            translated_texts.append(\"\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            response = client.translate_text(\n",
    "                parent=parent,\n",
    "                contents=[text],\n",
    "                target_language_code=target_language,\n",
    "            )\n",
    "            # The API returns a list of translations. We just need the first one.\n",
    "            translated_text = response.translations[0].translated_text\n",
    "            translated_texts.append(translated_text)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during translation: {e}\")\n",
    "            translated_texts.append(\"Translation Error\")\n",
    "\n",
    "    # Add the new column with the translated text to the DataFrame.\n",
    "    new_column_name = f\"{column_to_translate}_en\"\n",
    "    df[new_column_name] = translated_texts\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b11a1599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_single_mistral(text, model=\"mistral-embed\", lock=None, max_retries=5, base_wait=5):\n",
    "    \"\"\"\n",
    "    Generate Mistral embeddings for Slovak parliamentary transcription effectiveness analysis\n",
    "    Returns only the embedding vector for 2010-2023 corpus research\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return None\n",
    "    \n",
    "    # Check if client is properly initialized\n",
    "    global client_mistral\n",
    "    if client_mistral is None:\n",
    "        print(\"❌ Mistral client not initialized for Slovak parliamentary analysis\")\n",
    "        return None\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client_mistral.embeddings.create(\n",
    "                model=model, \n",
    "                inputs=[text]  # Correct parameter for Mistral API\n",
    "            )\n",
    "            \n",
    "            # Extract only the embedding vector from response\n",
    "            if hasattr(response, \"data\") and isinstance(response.data, list) and len(response.data) > 0:\n",
    "                # Get the embedding object\n",
    "                embedding_obj = response.data[0]\n",
    "                \n",
    "                # Extract vector from embedding object\n",
    "                if hasattr(embedding_obj, 'embedding'):\n",
    "                    return embedding_obj.embedding  # Return just the vector\n",
    "                elif isinstance(embedding_obj, dict) and 'embedding' in embedding_obj:\n",
    "                    return embedding_obj['embedding']  # Return just the vector\n",
    "                else:\n",
    "                    print(f\"⚠️ Unexpected Mistral response structure: {type(embedding_obj)}\")\n",
    "                    return None\n",
    "            else:\n",
    "                print(\"⚠️ No embeddings in Mistral response for Slovak parliamentary text\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            if \"rate limit\" in str(e).lower() or \"429\" in str(e):\n",
    "                wait = base_wait * (2 ** attempt)\n",
    "                print(f\"Rate limit hit. Waiting {wait}s before retrying (attempt {attempt+1}/{max_retries})...\")\n",
    "                time.sleep(wait)\n",
    "            else:\n",
    "                print(f\"Mistral embedding error: {e}\")\n",
    "                return None\n",
    "    \n",
    "    print(\"Max retries reached for Mistral embedding. Skipping.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3700c60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_truncated_prepis_voyage(df, model, input_type, output_dimension, text_column, out_column, batch_size=25, delay=60):\n",
    "    vo = voyageai.Client()\n",
    "    texts = df[text_column].tolist()\n",
    "    embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        try:\n",
    "            result = vo.embed(\n",
    "                batch,\n",
    "                model=model,\n",
    "                input_type=input_type,\n",
    "                output_dimension=output_dimension\n",
    "            )\n",
    "            embeddings.extend(result.embeddings)\n",
    "        except voyageai.error.RateLimitError:\n",
    "            print(\"Rate limit hit, waiting before retrying...\")\n",
    "            time.sleep(delay)\n",
    "            # Retry the same batch\n",
    "            result = vo.embed(\n",
    "                batch,\n",
    "                model=model,\n",
    "                input_type=input_type,\n",
    "                output_dimension=output_dimension\n",
    "            )\n",
    "            embeddings.extend(result.embeddings)\n",
    "    df[out_column] = embeddings\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ada6cda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_gemini_google(df, text_column, out_column=\"gemini-embedding-exp-03-07\", output_dim=3072, batch_size=16):\n",
    "    \"\"\"\n",
    "    Embed texts from a DataFrame column using Gemini (Google) embedding API.\n",
    "    \"\"\"\n",
    "    client = genai.Client()\n",
    "    embeddings = []\n",
    "    texts = df[text_column].tolist()\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        for text in batch:\n",
    "            try:\n",
    "                result = client.models.embed_content(\n",
    "                    model=\"gemini-embedding-001\",\n",
    "                    contents=text,\n",
    "                    config=types.EmbedContentConfig(output_dimensionality=output_dim)\n",
    "                )\n",
    "                embeddings.append(result.embedding)\n",
    "            except Exception as e:\n",
    "                print(f\"Embedding error: {e}\")\n",
    "                embeddings.append(None)\n",
    "    df[out_column] = embeddings\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dff3e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_openai_batch(df, text_column, out_column, model=\"text-embedding-3-large\", batch_size=100, client=None):\n",
    "    \"\"\"\n",
    "    Embed texts in batches using OpenAI API (works for both small and large models).\n",
    "    \"\"\"\n",
    "    if client is None:\n",
    "        from openai import OpenAI\n",
    "        import os\n",
    "        client = OpenAI(api_key=os.getenv('open_API_KEY'))\n",
    "    texts = df[text_column].tolist()\n",
    "    embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        try:\n",
    "            response = client.embeddings.create(input=batch, model=model)\n",
    "            batch_embeddings = [item.embedding for item in response.data]\n",
    "            embeddings.extend(batch_embeddings)\n",
    "        except Exception as e:\n",
    "            print(f\"OpenAI embedding error: {e}\")\n",
    "            embeddings.extend([None]*len(batch))\n",
    "    df[out_column] = embeddings\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e342ccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_mistral_rowwise(df, model=\"mistral-embed\", text_column=\"truncated_prepis_en\", out_column=\"mistral_embedings_eng\"):\n",
    "    \"\"\"\n",
    "    Generate Mistral embeddings for Slovak parliamentary effectiveness analysis\n",
    "    Embeds each row individually with progress tracking for 2010-2023 corpus\n",
    "    Returns only embedding vectors (not embedding objects)\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    successful_embeddings = 0\n",
    "    \n",
    "    for text in tqdm(df[text_column], desc=\"Mistral embedding for Slovak parliament\"):\n",
    "        emb = embed_single_mistral(text, model)\n",
    "        embeddings.append(emb)\n",
    "        if emb is not None:\n",
    "            successful_embeddings += 1\n",
    "    \n",
    "    df[out_column] = embeddings\n",
    "    print(f\"✅ Mistral embeddings: {successful_embeddings}/{len(embeddings)} Slovak parliamentary speeches processed\")\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "89204334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_gemini_google(df, text_column, out_column=\"gemini-embedding-exp-03-07_eng\", output_dim=3072, batch_size=16):\n",
    "    \"\"\"\n",
    "    Generate Gemini embeddings for Slovak parliamentary transcription effectiveness analysis\n",
    "    Specialized for English-translated Slovak parliamentary speeches (2010-2023 corpus)\n",
    "    Novel procedures for cross-linguistic embedding evaluation on Slovak language data\n",
    "    \"\"\"\n",
    "    client = genai.Client()\n",
    "    embeddings = []\n",
    "    texts = df[text_column].tolist()\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Gemini embedding for Slovak parliament\"):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        for text in batch:\n",
    "            try:\n",
    "                # Correct API call for Gemini embeddings\n",
    "                result = client.models.embed_content(\n",
    "                    model=\"gemini-embedding-001\",\n",
    "                    contents=text,\n",
    "                    config=types.EmbedContentConfig(output_dimensionality=output_dim)\n",
    "                )\n",
    "                \n",
    "                # Fix: Extract embedding vector from response\n",
    "                # The embedding is in result.embeddings[0].values\n",
    "                if hasattr(result, 'embeddings') and len(result.embeddings) > 0:\n",
    "                    embedding_vector = result.embeddings[0].values\n",
    "                    embeddings.append(embedding_vector)\n",
    "                else:\n",
    "                    print(f\"No embeddings found in response for Slovak parliamentary text\")\n",
    "                    embeddings.append(None)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Gemini embedding error for Slovak parliamentary analysis: {e}\")\n",
    "                embeddings.append(None)\n",
    "    \n",
    "    df[out_column] = embeddings\n",
    "    print(f\"✅ Gemini embeddings generated for {len([e for e in embeddings if e is not None])}/{len(embeddings)} Slovak parliamentary speeches\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94977457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- OpenAI embedding function (works for both small and large) ---\n",
    "def embed_openai_batch(df, text_column, out_column, model=\"text-embedding-3-large\", batch_size=100, client=None):\n",
    "    if client is None:\n",
    "        client = OpenAI(api_key=os.getenv('open_API_KEY'))\n",
    "    texts = df[text_column].tolist()\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=f\"OpenAI {model} embedding\"):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        try:\n",
    "            response = client.embeddings.create(input=batch, model=model)\n",
    "            batch_embeddings = [item.embedding for item in response.data]\n",
    "            embeddings.extend(batch_embeddings)\n",
    "        except Exception as e:\n",
    "            print(f\"OpenAI embedding error: {e}\")\n",
    "            embeddings.extend([None]*len(batch))\n",
    "    df[out_column] = embeddings\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31610e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating column 'truncated_prepis'...\n"
     ]
    }
   ],
   "source": [
    "df = translate_dataframe_column(df, column_to_translate=\"truncated_prepis\", target_language=\"en\", project_id=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33baf35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191      32.. Mr. Fico, I am the one who removed Harabi...\n",
       "197      96.Good afternoon. Dear Minister, Dear Preside...\n",
       "234      10..I am speaking in the debate on this agenda...\n",
       "244      66..Before I say when this will be voted on, I...\n",
       "332      253.. Mr. Minister, I am not that fast. Dear M...\n",
       "                               ...                        \n",
       "19888    34., Mr. Chairman, colleagues, I also consider...\n",
       "19890    18.. Dear Mr. Chairman, Dear Mr. Minister, col...\n",
       "19892    113..Dear Mr. Chairman, Mr. Minister, esteemed...\n",
       "19893    69., Mr. Chairman, esteemed colleagues, collea...\n",
       "19915    162.. In the first reading, I spoke at length,...\n",
       "Name: truncated_prepis_en, Length: 522, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['truncated_prepis_en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0ae770d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mistral embedding for Slovak parliament: 100%|██████████| 522/522 [02:03<00:00,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Mistral embeddings: 522/522 Slovak parliamentary speeches processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = embed_mistral_rowwise(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eaa0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = embed_truncated_prepis_voyage(df, model=\"voyage-3-large\", input_type=\"document\", output_dimension=2048, text_column=\"truncated_prepis_en\", out_column=\"voyage-3-large_embeddings_eng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9f2572eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemini embedding for Slovak parliament: 100%|██████████| 33/33 [02:53<00:00,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Gemini embeddings generated for 522/522 Slovak parliamentary speeches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Gemini (Google) embedding\n",
    "df = embed_gemini_google(df, text_column=\"truncated_prepis_en\", out_column=\"gemini-embedding-exp-03-07_eng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95615205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenAI text-embedding-3-large embedding: 100%|██████████| 6/6 [00:54<00:00,  9.11s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# OpenAI large embedding\n",
    "df = embed_openai_batch(df, text_column=\"truncated_prepis_en\", out_column=\"openAI_embedding_3076_eng\", model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bf60e450",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenAI text-embedding-3-small embedding: 100%|██████████| 6/6 [00:11<00:00,  1.91s/it]\n"
     ]
    }
   ],
   "source": [
    "# OpenAI small embedding\n",
    "df = embed_openai_batch(df, text_column=\"truncated_prepis_en\", out_column=\"openAI_embedding_small_eng\", model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "079a0515",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(r\"..\\data\\df_to_app_with_openAI_S_L_voyage_gdoogle_mistral_embeddings_navrh_zakona_obdobie_8_core_clear_eng.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7a462e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for English embedding evaluation\n",
    "EMB_COLS_ENG = [\n",
    "    \"gemini-embedding-exp-03-07_eng\",\n",
    "    \"openAI_embedding_3076_eng\", \n",
    "    \"openAI_embedding_small_eng\",\n",
    "    \"mistral_embedings_eng\",  \n",
    "    \"voyage-3-large_embeddings_eng\"   \n",
    "]\n",
    "\n",
    "LABEL_COL = \"Predkladateľ\"\n",
    "TEXT_COL = \"translated_text\"  # English translated text column\n",
    "SEED = 0\n",
    "K_ELBOW_MAX = 15\n",
    "UMAP_NN = 15\n",
    "UMAP_DIST = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c4914d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Precision / recall / F1 after majority‑vote mapping\n",
    "    (now works whether y_pred is ndarray or Series)\n",
    "    \"\"\"\n",
    "    # ensure Pandas objects\n",
    "    if not isinstance(y_true, pd.Series):\n",
    "        y_true = pd.Series(y_true)          # safety\n",
    "    if not isinstance(y_pred, pd.Series):\n",
    "        y_pred = pd.Series(y_pred, index=y_true.index)\n",
    "\n",
    "    # contingency table: rows = clusters, cols = true labels\n",
    "    ct = pd.crosstab(y_pred, y_true)\n",
    "\n",
    "    # majority label for every cluster\n",
    "    best_label = ct.idxmax(axis=1).to_dict()       # cluster → label\n",
    "\n",
    "    # convert prediction to that majority label (majority vote)\n",
    "    y_map = y_pred.map(best_label)\n",
    "\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_map, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    return dict(precision=prec, recall=rec, f1=f1,\n",
    "                v_measure=v_measure_score(y_true, y_pred),\n",
    "                ari=adjusted_rand_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4848f804",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def elbow_k(X, k_max=K_ELBOW_MAX):\n",
    "    sil = []\n",
    "    for k in range(2, k_max+1):\n",
    "        lab = KMeans(k, n_init=20, random_state=0).fit_predict(X)\n",
    "        sil.append(silhouette_score(X, lab, metric=\"cosine\"))\n",
    "    k_star = np.argmax(sil) + 2       # highest silhouette\n",
    "    return k_star, np.arange(2, k_max+1), np.array(sil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ac8c840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_write(df, emb_col, label_col=\"Predkladateľ\",\n",
    "                       k_fixed=None, k_max=None,\n",
    "                       write_prefix=\"cluster\"):\n",
    "    \"\"\"\n",
    "    Cluster Slovak parliamentary speeches and add cluster columns to DataFrame\n",
    "    Returns both metrics and the updated DataFrame with cluster columns\n",
    "    \"\"\"\n",
    "    X = np.vstack(df[emb_col]).astype(\"float32\")\n",
    "    y = df[label_col].astype(\"category\").cat.codes\n",
    "\n",
    "    # ── elbow variant ────────────────────────────────────────────\n",
    "    k_star, ks, sils = elbow_k(X, k_max)\n",
    "    lab_elbow = KMeans(k_star, n_init=20, random_state=SEED).fit_predict(X)\n",
    "    df[f\"{write_prefix}_{emb_col}_elbow\"] = lab_elbow\n",
    "\n",
    "    # ── fixed‑k variant (k_fixed = real #labels) ────────────────\n",
    "    if k_fixed is None:\n",
    "        k_fixed = df[label_col].nunique()\n",
    "    lab_fixed = KMeans(k_fixed, n_init=20, random_state=SEED).fit_predict(X)\n",
    "    df[f\"{write_prefix}_{emb_col}_fixed\"] = lab_fixed\n",
    "\n",
    "    # ── metrics (using the same cluster_metrics() as before) ────\n",
    "    m_elbow = cluster_metrics(y, lab_elbow) | {\"k\": k_star}\n",
    "    m_fixed = cluster_metrics(y, lab_fixed) | {\"k\": k_fixed}\n",
    "\n",
    "    # Return both metrics AND the updated DataFrame\n",
    "    return {\n",
    "        \"elbow\": m_elbow,\n",
    "        \"fixed\": m_fixed,\n",
    "        \"elbow_curve\": (ks, sils),\n",
    "        \"lab_elbow\": lab_elbow,      \n",
    "        \"lab_fixed\": lab_fixed,\n",
    "        \"df_updated\": df          # <<<< NOW RETURNS UPDATED DataFrame\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2af5dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_real = df[LABEL_COL].nunique()\n",
    "store = {}\n",
    "df_cores_with_clusters = {}  # Store updated df_core with cluster columns\n",
    "\n",
    "print(f\"🏛️ SLOVAK PARLIAMENTARY CLUSTERING ANALYSIS\")\n",
    "print(f\"📊 Real ministries (Predkladateľ): {k_real}\")\n",
    "print(f\"🔍 Search range: k=2 to k={K_ELBOW_MAX}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for emb in EMB_COLS_ENG:\n",
    "    mask_col = f\"core_{emb[:-4]}\"\n",
    "    if mask_col not in df.columns:\n",
    "        raise ValueError(f\"Missing mask column '{mask_col}' – \"\n",
    "                         \"run add_core_masks() first.\")\n",
    "    \n",
    "    df_core = df[df[mask_col]].copy()  # Keep only core speeches\n",
    "    print(f\"▶ {emb}  |  rows kept: {len(df_core)}\")\n",
    "\n",
    "    # Get clustering results\n",
    "    result = evaluate_and_write(\n",
    "        df_core,\n",
    "        emb_col=emb,\n",
    "        label_col=LABEL_COL,\n",
    "        k_fixed=k_real,\n",
    "        k_max=K_ELBOW_MAX,\n",
    "        write_prefix=\"cluster\"\n",
    "    )\n",
    "    \n",
    "    store[emb] = result\n",
    "    df_cores_with_clusters[emb] = result[\"df_updated\"]  # Store updated df_core\n",
    "    \n",
    "\n",
    "# Enhanced table of metrics with k values shown\n",
    "rows = []\n",
    "for emb, d in store.items():\n",
    "    rows.append({\n",
    "        \"embedding\": emb, \n",
    "        \"mode\": \"elbow\", \n",
    "        \"k_used\": d[\"elbow\"][\"k\"],     # Show actual k found\n",
    "        **{k:v for k,v in d[\"elbow\"].items() if k != \"k\"}\n",
    "    })\n",
    "    rows.append({\n",
    "        \"embedding\": emb, \n",
    "        \"mode\": \"fixed\", \n",
    "        \"k_used\": d[\"fixed\"][\"k\"],     # Show actual k used\n",
    "        **{k:v for k,v in d[\"fixed\"].items() if k != \"k\"}\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(rows).round(3)\n",
    "\n",
    "print(\"\\n📈 CLUSTERING EFFECTIVENESS RESULTS:\")\n",
    "print(\"(k_used = actual number of clusters found/used)\")\n",
    "display(metrics_df)\n",
    "\n",
    "# Validation: Check if elbow k matches visualization peaks\n",
    "print(\"\\n🔍 ELBOW METHOD VALIDATION:\")\n",
    "for emb, d in store.items():\n",
    "    ks, sils = d[\"elbow_curve\"]\n",
    "    peak_k = ks[np.argmax(sils)]\n",
    "    reported_k = d[\"elbow\"][\"k\"]\n",
    "    match = \"✅\" if peak_k == reported_k else \"❌\"\n",
    "    print(f\"{match} {emb}: peak at k={peak_k}, reported k={reported_k}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
